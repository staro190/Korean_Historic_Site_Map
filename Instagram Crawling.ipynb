{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 동적 웹 크롤링 라이브러리\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "# 알림창 등을 회피하기 위한 키보드 라이브러리\n",
    "import pyautogui\n",
    "\n",
    "# 각종 라이브러리\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 유적지 데이터셋 읽기 및 유적지명 리스트 생성\n",
    "df = pd.read_csv('KC_507_LLR_HISTST_2022_test.csv')\n",
    "dest_lst = df['prompt'].values.tolist()\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 크롤링 시작\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.instagram.com')\n",
    "time.sleep(3)\n",
    "\n",
    "# id, pw 입력 및 로그인\n",
    "ID = 'id'\n",
    "pw = 'pw'\n",
    "\n",
    "# ID 문자열 전송\n",
    "input_id = driver.find_elements(By.CSS_SELECTOR, 'input')[0]\n",
    "input_id.clear()\n",
    "input_id.send_keys(ID)\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# PW 문자열 전송\n",
    "input_pw = driver.find_elements(By.CSS_SELECTOR, 'input')[1]\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(pw)\n",
    "\n",
    "# 로그인\n",
    "time.sleep(2)\n",
    "input_pw.submit()\n",
    "time.sleep(10)\n",
    "\n",
    "# 팝업창 닫기\n",
    "pyautogui.press('tab')\n",
    "time.sleep(1)\n",
    "pyautogui.press('enter')\n",
    "time.sleep(3)\n",
    "pyautogui.press('esc')\n",
    "time.sleep(1)\n",
    "\n",
    "# 검색창 열기\n",
    "driver.find_elements(By.CSS_SELECTOR,'[aria-label=\"검색\"]')[0].click()\n",
    "time.sleep(1)\n",
    "input_sch = driver.find_elements(By.CSS_SELECTOR, 'input')[0]\n",
    "\n",
    "#7627개 유적지 순회\n",
    "for i in range(len(dest_lst)):\n",
    "    \n",
    "    # 500개 검색 후 세션 해제 방지를 위한 페이지 새로고침\n",
    "    if i%500 == 0 and i!=0:\n",
    "        driver.refresh()\n",
    "        time.sleep(10)\n",
    "        driver.find_elements(By.CSS_SELECTOR,'[aria-label=\"검색\"]')[0].click()\n",
    "        time.sleep(1)\n",
    "        input_sch = driver.find_elements(By.CSS_SELECTOR, 'input')[0]\n",
    "    \n",
    "    # 유적지명 검색\n",
    "    word = dest_lst[i]\n",
    "    input_sch.clear()\n",
    "    input_sch.send_keys(word)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 결과 HTML 별도 TXT 파일로 저장\n",
    "    html = driver.page_source\n",
    "    with open('./html_save/'+str(word)+'.txt','w',encoding = 'utf16') as f:\n",
    "        temp = str(html)\n",
    "        # 용량을 줄이기 위해 불필요한 부분 제거 후 저장\n",
    "        temp = temp[temp.find('프로필 사진'):temp.find('회원님을 위한 추천')]\n",
    "        f.write(temp)\n",
    "\n",
    "    print(word, ' Complete')\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석용 라이브러리 \n",
    "import pandas as pd\n",
    "# 파일시스템 제어용 라이브러리\n",
    "import os\n",
    "\n",
    "# html 저장 위치 접근 및 DataFrame 준비\n",
    "path_dir = './html_save/'\n",
    "file_list = os.listdir(path_dir)\n",
    "df = pd.DataFrame({'SITE':[], 'TAGS':[]})\n",
    "\n",
    "# txt 파일로 저장해둔 html 순회\n",
    "for index, name in enumerate(file_list):\n",
    "    \n",
    "    # 파일 데이터 문자열로 읽어오기\n",
    "    f=open('./html_save/'+name,\"rt\",encoding = 'utf16')\n",
    "    tmp = ''\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        tmp = tmp+line\n",
    "        if line == '' :\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    # 문자열에서 게시물 개수를 탐색\n",
    "    h_site = name.replace('.txt','')\n",
    "    count = 0\n",
    "    start = tmp.find('>#'+h_site+'<')\n",
    "    if start>=0:\n",
    "        pnt1 = tmp[start:].find('게시물')\n",
    "        pnt2 = tmp[start+pnt1:].find('<span>')\n",
    "        end = tmp[start+pnt1+pnt2:].find('</span>')\n",
    "        hashtags = tmp[pnt1+pnt2+start:pnt1+pnt2+start+end].replace('<span>','')\n",
    "        \n",
    "        # 태그 수 만개 이상, 한글표시 숫자로 변경\n",
    "        ten_thou = hashtags.find('만')\n",
    "        if ten_thou < 0:\n",
    "            count = int(hashtags)\n",
    "        else:\n",
    "            count = int(float(hashtags.replace('만',''))*10000)\n",
    "        \n",
    "    # DataFrame에 유적지명 | 해시태그 수 로 저장\n",
    "    print(h_site, count)\n",
    "    df.loc[index, 'SITE'] = h_site\n",
    "    df.loc[index, 'TAGS'] = count\n",
    "    \n",
    "display(df)\n",
    "\n",
    "df.to_csv('Insta_Analyze.csv', index=False, encoding='utf16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석 및 시각화 라이브러리\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 해시태그 데이터셋 불러오기\n",
    "insta = pd.read_csv('insta_tags.csv', encoding='cp949')\n",
    "insta['TAGS'] = insta['TAGS'].astype('long')\n",
    "\n",
    "# 태그수가 0인 데이터와 0 초과인 데이터 분리\n",
    "df = insta[insta['TAGS']>0]\n",
    "df0 = insta[insta['TAGS']==0]\n",
    "\n",
    "# 0초과 데이터셋을 6개로 데이터 수 균등 분할함\n",
    "labels = [1,2,3,4,5,6]\n",
    "df2 = pd.qcut(df['TAGS'],6,labels = labels)\n",
    "#분할 경계값 확인\n",
    "print(df2.unique())\n",
    "\n",
    "\n",
    "# 분할된 데이터셋의 개수를 확인\n",
    "temp = pd.value_counts(df2)\n",
    "print(temp)\n",
    "\n",
    "# 태그가 0인 데이터의 개수 확인\n",
    "print(df0.count())\n",
    "\n",
    "# 히스토그램을 통해 균등한 분할이 이루어졌는지 확인\n",
    "values = [df0['TAGS'].count(), temp[1], temp[2], temp[3], temp[4], temp[5], temp[6]]\n",
    "labels = [0,1,2,3,4,5,6]\n",
    "plt.bar(labels, values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
